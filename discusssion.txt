NB: supplemental information can be found in README.md
    since this assignment is hosted on github,
    the viewing of the former is nicer here: https://github.com/flupe/simplex




SUPPLEMENTARY PIVOT RULES
=========================

3 more pivot rules were implemented:

- Random rule
  We select the entering variable from valid candidates at random.
  Then from all suitable leaving variables, we pick one at random too.

- Smallest Coefficient rule
  Essentially a little twist on the Largest Coefficient rule.
  Instead of choosing the entering variable whose coefficient in the objective function is the largest,
  we pick the one with the smallest one.
  As could have been expected, it performs terribly.

- Maximum Increase rule.
  This last rule definitely is the most interesting.
  For every entering candidate, we select an associated leaving variable as we would have done with Bland's rule.
  With this, we can compute the increase in the objective function if this candidate variable were to enter the basis.
  Finally, we pick the entering candidate (and its associated leaving variable) for which this increase is the maximum.

  All three of those rules (plus the ones from the subject) were implemented in `pivot.py`.




COMPARISON OF PIVOT RULES
========================

Here is a qualitative comparison of the different pivot rules.
Edge cases for specific rules are discussed in the next section.

After running the many tests with every pivot rules,
a qualitative ordering of the various pivot rules can be established as such:
(where A < B means "A requires less pivoting than B", less is better)

Maximum Increase  <  Largest Coefficient  <  Bland  <  Random  <  Smallest Coefficient

- If the Maximum Increase rule definitely requires less pivoting than the others, finding which entering & leaving variables
  to pick is more computationnaly intensive, since we have to find the corresponding leaving variables
  to EVERY entering candidate, then find which couple is the most efficient to increase the objective function.
  Meaning if we were to compare running time, despite this rule almost always exhibiting a smaller number of pivot operations,
  it still runs slower than the next other two at times.

- The Random rule really has an unpredictable behavior.
  It mostly orbits around Bland's rule running time & number of pivot operations.
  Sometimes it's really bad, sometimes just excellent. In other words, unreliable.

- The Smallest Coefficient is terribly bad. Not much to add here.
  That's what you should expect when you pick the variable with the least influence on the objective function to enter the basis.




NOTABLE LINEAR PROGRAMS
=======================

3 noteworthy examples have been included to the `tests/` directory.

- example1
  This simple example illustrates how cycling can happen when using the Largest Coefficient rule.
  While this LP instance is solved in only `7` pivot operations using *Bland's rule*,
  it simply never ends when using the former.
  We essentially cycle through the same basis, without improving our solution.

- example2
  This example was generated by running `python3 worst_bland.py 20`, and is a construction of the Klee-Minty cube.
    => http://users.uom.gr/~samaras/pdf/BC6.pdf
  In this paper, it is showed that Bland's rule performs exponentially on this problem.
  In our example, it needs `21891` pivot operations to find the optimal solution,
  whereas the Largest Coefficient rule ends in only one step.
  However, the same paper shows that with a slightly modified configuration,
  we can construct a configuration in which this other rule performs exponentially too. Hence,

- example3
  This example was generated by running `python3 worst_max.py 10`.
  It is the configuration mentionned earlier, which exhibits an exponential behavior from the Largest Coefficient rule.
  With d the number of variables in our configuration,
  this rule needs exactly 2^n - 1 pivot operations to find the optimal soluton.
  In our example, the Largest Coefficient rule leads to 1023 pivot operations,
  vastly outperformed by Bland's rule, requiring only 177 pivot operations.

These last two examples are still solved with only one pivot operation with the Maximum Increase rule.




PARAMETER SENSITIVITY
=====================

From the set of tests I was able to run this program on, it seems much more sensitive to the number of constraints
than the number of variables.
This phenomenon can be observed by generating feasible bounded LP problems with parameters `n=20, m=30`,
`n=20, m=60` and `n=60, m=30`.
This behavior is to be expected: for every M additional constraints, there are M additional slack variables added to the problem, and potentially even more additional variables, one for every `>=` constraints.


